# SOCIAL MEDIA SENTIMENT ANALYSIS

# 1. Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
from tqdm import tqdm
from wordcloud import WordCloud


# Set plotting style
plt.style.use("ggplot")

# 2. Read Data
df = pd.read_csv("C:\\Users\\CHAITALI JAIN\\Desktop\\Reviews.csv")


# 3. Display Basic Information
print(df.shape)
print(df.head(500))
print(f"Missing values:\n{df.isnull().sum()}")
print(df.dtypes)

# Rating Analyzes
print(f"Rating value count:\n{df['Score'].value_counts()}")

# Plot review count by star rating
df['Score'].value_counts().sort_index().plot(kind="bar", title="Count of Review by Star", figsize=(10, 5))
plt.xlabel("Review Stars")
plt.show()


# 4. Basic NLTK Tokenization and Tagging
example = df['Text'][50]  # Sample text for demonstration
print("Sample Text:")
print(example)

# Tokenize the sample text
tokens = nltk.word_tokenize(example)
print("\nFirst 10 Tokens:")
print(tokens[:10])

# Part-of-Speech Tagging
tagged = nltk.pos_tag(tokens)
print("\nFirst 10 Tagged Tokens:")
print(tagged[:10])

# Named Entity Recognition
entities = nltk.chunk.ne_chunk(tagged)
print("\nNamed Entities:")
entities.pprint()

# 5. Sentiment Analysis using VADER and TextBlob
sia = SentimentIntensityAnalyzer()

# Run polarity on a small sample text
sentiment = sia.polarity_scores(example)
print("\nSentiment Analysis")
print(sentiment)

# Run the polarity Score on the entire dataset
res = {}
for i, row in tqdm(df.iterrows(), total = len(df)):
#for i, row in df.head(50).iterrows():  # Limit processing to the first 50 rows
    Text = row["Text"]
    myid = row["Id"]
    res[myid] = sia.polarity_scores(Text)
# print (res)

# Convert results to a DataFrame for easier analysis
sentiment_df = pd.DataFrame(res).T
sentiment_df = sentiment_df.reset_index().rename(columns={'index': 'Id'})
df = df.merge(sentiment_df, on='Id')

# Step 2 - TextBlob Sentiment Analysis
df['textblob_polarity'] = df['Text'].apply(lambda x: TextBlob(x).sentiment.polarity)
df['textblob_subjectivity'] = df['Text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)
#print(f"TextBlob Sentiment Analysis:\n{df[['textblob_polarity', 'textblob_subjectivity']].head()}")


# Save the results to a new CSV file (optional)
output_path = "C:\\Users\\CHAITALI JAIN\\Desktop\\Reviews_with_Sentiment_Updated.csv"
try:
    df.to_csv(output_path, index=False)
    print(f"Results successfully saved to {output_path}")
except PermissionError as e:
    print(f"PermissionError: {e}")
except Exception as e:
    print(f"An error occurred: {e}")

# 6. Visualize Sentiment Trends
# Reload Data with Sentiment Scores
df = pd.read_csv("C:\\Users\\CHAITALI JAIN\\Desktop\\Reviews_with_Sentiment_Updated.csv")

# Plot VADER Results
gr = sns.barplot(data=df, x = "Score", y = "Compound")
gr.set_title("Compound Score by Amazon Star Review")
plt.show()

fig, axs = plt.subplots(1,3, figsize = (15,5))
sns.barplot(data=df, x = "Score", y= "Pos", ax = axs[0])
sns.barplot(data=df, x = "Score", y= "Neu", ax = axs[1])
sns.barplot(data=df, x = "Score", y= "Neg", ax = axs[2])
axs[0].set_title("Positive")
axs[1].set_title("Neutral")
axs[2].set_title("Negative")
plt.tight_layout()
plt.show()

# Distribution of Sentiment Scores
plt.figure(figsize=(12,6))
sns.histplot(df['Compound'], kde = True, bins = 30)
plt.title('Distribution of Compound Sentiment Score')
plt.xlabel("Compound Sentiment Score")
plt.ylabel("Frequency")
plt.show()

# Time Series Analysis
df['Time'] = pd.to_datetime(df['Time'], unit='s')  # Assuming 'Time' column is in UNIX timestamp format
df.set_index('Time', inplace=True)
df['Compound'].resample('ME').mean().plot(title='Average Sentiment Over Time (Monthly)', figsize=(12, 6))
plt.ylabel('Average Compound Sentiment Score')
plt.show()

# 7. Generate Word Cloud For Frequent Words
all_word = ' '.join([text for text in df['Text']])
wordcloud = WordCloud(width = 800, height = 400, random_state=21, max_font_size = 110).generate(all_word)

plt.figure(figsize=(10,7))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.title('Most Frequent Words in Reviews')
plt.show()


# 8. Compare Sentiment Scores by Rating
# Comparison of Average Sentiment Scores by Rating
avg_sentiment_Score = df.groupby("Score")[['pos','neu','neg','compound']].mean()
print(f"Average Sentiment Scores By Rating: \n{avg_sentiment_Score}")

avg_sentiment_Score.plot(kind = "bar", figsize = (12,8))
plt.title("Average Sentiment Score By Rating")
plt.xlabel("Rating")
plt.ylabel("Average Score")
plt.show()

# Verification and Comparison
# Verify DataFrame Columns
print(f"Columns in DataFrame: {df.columns.tolist()}")

# Print the first few rows to check the result
print(f"Updated DataFrame with VADER and TextBlob Sentiment Scores:\n{df.head()}")

# Comparison of VADER and TextBlob
plt.figure(figsize=(12, 6))
sns.histplot(df['compound'], color='blue', label='VADER', kde=True)
sns.histplot(df['textblob_polarity'], color='red', label='TextBlob', kde=True)
plt.title('Comparison of VADER and TextBlob Sentiment Scores')
plt.xlabel('Sentiment Score')
plt.ylabel('Frequency')
plt.legend()
plt.show()

